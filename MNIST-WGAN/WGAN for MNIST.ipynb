{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A WGAN generating fake MNIST signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns \n",
    "import sys \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "import iisignature as signature\n",
    "\n",
    "from Tools import generateur_donnees, generate_noise, extrapolate_signature, gradient_penalty, extrapolate_multiple_signatures\n",
    "from WGAN import *\n",
    "from Training_loop_MNIST import train_MNIST\n",
    "from MNIST_Plots import plot_training_results\n",
    "\n",
    "from get_MNIST_sig import MNIST_sigs\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import trained model Training "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This WGAN-GP tries to mimic signatures of MNIST handdrawn PenDigits. Training is done in a separate Python script to avoid kernel collapse.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_size = 8\n",
    "\n",
    "signature_length = signature.siglength(2,8)\n",
    "\n",
    "WGAN = generateur(noise_size,signature_length*2,signature_length)\n",
    "\n",
    "#Change path to choose the model you want to load \n",
    "\n",
    "WGAN.load_state_dict(torch.load('trained_models/generator_int_3_sigorder_8_iterations_2000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import true signatures \n",
    "\n",
    "true_data,nothing = MNIST_sigs(3,8)\n",
    "true_data = true_data[np.random.choice(np.arange(500),10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'erreur_discrim_sur_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-3c7f169f4279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moutput_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_fake\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplot_training_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0merreur_discrim_sur_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merreur_discrim_sur_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_noise_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_noise_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'erreur_discrim_sur_true' is not defined"
     ]
    }
   ],
   "source": [
    "test_noise_size = 10\n",
    "\n",
    "noise_size = 8\n",
    "\n",
    "new_noise = torch.normal(mean = torch.zeros(test_noise_size,noise_size)).float()\n",
    "\n",
    "output_fake = WGAN.forward(new_noise)\n",
    "\n",
    "output_fake = output_fake.detach().numpy()\n",
    "\n",
    "plot_training_results(fake_sig = output_fake, true_sig = true_data,erreur_discrim_sur_true=erreur_discrim_sur_true,test_noise_size = test_noise_size,gradient=gradient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export fake signatures for further use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export fake signatures to csv file \n",
    "\n",
    "new_noise = torch.normal(mean = torch.zeros(1000,noise_size)).float()\n",
    "\n",
    "fake_sig = WGAN(new_noise)\n",
    "\n",
    "fake_sig = fake_sig.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(fake_sig).to_csv(\"fake_sig_integer_3_order_8_noise_8.csv\", header = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
